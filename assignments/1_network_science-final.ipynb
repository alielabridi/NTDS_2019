{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [NTDS'19] assignment 1: network science\n",
    "[ntds'19]: https://github.com/mdeff/ntds_2019\n",
    "\n",
    "[Eda Bayram](https://lts4.epfl.ch/bayram), [EPFL LTS4](https://lts4.epfl.ch) and\n",
    "[Nikolaos Karalias](https://people.epfl.ch/nikolaos.karalias), [EPFL LTS2](https://lts2.epfl.ch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students\n",
    "\n",
    "* Team: 4 (Yann Yanis Bouquet, Ali El Abridi, Tariq Kalim, Jonas Müller)\n",
    "* Students: Jonas Müller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "Grading:\n",
    "* The first deadline is for individual submissions. The second deadline is for the team submission.\n",
    "* All team members will receive the same grade based on the team solution submitted on the second deadline.\n",
    "* As a fallback, a team can ask for individual grading. In that case, solutions submitted on the first deadline are graded.\n",
    "* Collaboration between team members is encouraged. No collaboration between teams is allowed.\n",
    "\n",
    "Submission:\n",
    "* Textual answers shall be short. Typically one to two sentences.\n",
    "* Code has to be clean.\n",
    "* You cannot import any other library than we imported.\n",
    "  Note that Networkx is imported in the second section and cannot be used in the first.\n",
    "* When submitting, the notebook is executed and the results are stored. I.e., if you open the notebook again it should show numerical results and plots. We won't be able to execute your notebooks.\n",
    "* The notebook is re-executed from a blank state before submission. That is to be sure it is reproducible. You can click \"Kernel\" then \"Restart Kernel and Run All Cells\" in Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The purpose of this milestone is to explore a given dataset, represent it by network by constructing different graphs. In the first section, you will analyze the network properties. In the second section, you will explore various network models and find out the network model fitting the ones you construct from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cora Dataset\n",
    "\n",
    "The [Cora dataset](https://linqs.soe.ucsc.edu/node/236) consists of scientific publications classified into one of seven research fields. \n",
    "\n",
    "* **Citation graph:** the citation network can be constructed from the connections given in the `cora.cites` file.\n",
    "* **Feature graph:** each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from the dictionary and its research field, given in the `cora.content` file. The dictionary consists of 1433 unique words. A feature graph can be constructed using the Euclidean distance between the feature vector of the publications.\n",
    "\n",
    "The [`README`](data/cora/README) provides details about the content of [`cora.cites`](data/cora/cora.cites) and [`cora.content`](data/cora/cora.content)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Network Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# show all output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Construct a Citation Graph and a Feature Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the `cora.content` file into a Pandas DataFrame by setting a header for the column names. Check the `README` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "N_WORDS = 1433\n",
    "word_n_list = [f'w_{x}' for x in list(range(N_WORDS))]\n",
    "column_list = [\"paper_id\"] + word_n_list + [\"class_label\"]\n",
    "\n",
    "pd_content = pd.read_csv('data/cora/cora.content', delimiter='\\t', names=column_list) \n",
    "pd_content.head()\n",
    "nr_of_papers = len(pd_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the number of papers contained in each of the reasearch fields.\n",
    "\n",
    "**Hint:** You can use the `value_counts()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_content[\"class_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select all papers from a field of your choice and store their feature vectors into a NumPy array.\n",
    "Check its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_field = \"Theory\"\n",
    "my_field_mask = pd_content[\"class_label\"] == my_field\n",
    "\n",
    "features = pd_content.loc[my_field_mask].drop([\"paper_id\",\"class_label\"], axis=1).to_numpy()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $D$ be the Euclidean distance matrix whose $(i,j)$ entry corresponds to the Euclidean distance between feature vectors $i$ and $j$.\n",
    "Using the feature vectors of the papers from the field which you have selected, construct $D$ as a Numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = features[:, :, None] - features[:, :, None].T\n",
    "distance = np.sqrt((distance**2).sum(1))\n",
    "distance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the mean pairwise distance $\\mathbb{E}[D]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_distance = distance.mean()\n",
    "mean_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot an histogram of the euclidean distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(8, 4))\n",
    "plt.title(\"Histogram of Euclidean distances between papers\")\n",
    "plt.hist(distance.flatten());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create an adjacency matrix for the papers by thresholding the Euclidean distance matrix.\n",
    "The resulting (unweighted) adjacency matrix should have entries\n",
    "$$ A_{ij} = \\begin{cases} 1, \\; \\text{if} \\; d(i,j)< \\mathbb{E}[D], \\; i \\neq j, \\\\ 0, \\; \\text{otherwise.} \\end{cases} $$\n",
    "\n",
    "First, let us choose the mean distance as the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = mean_distance\n",
    "A_feature = (distance < threshold).astype(int) \n",
    "A_feature = A_feature - np.diag(np.ones(A_feature.shape[0]))\n",
    "\n",
    "np.count_nonzero(A_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read the `cora.cites` file and construct the citation graph by converting the given citation connections into an adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_cites = np.genfromtxt('data/cora/cora.cites', delimiter='\\t')\n",
    "\n",
    "def replace_with_dict(ar, dic):\n",
    "    # Extract out keys and values\n",
    "    k = np.array(list(dic.keys()))\n",
    "    v = np.array(list(dic.values()))\n",
    "\n",
    "    # Get argsort indices\n",
    "    sidx = k.argsort()\n",
    "\n",
    "    # Drop the magic bomb with searchsorted to get the corresponding\n",
    "    # places for a in keys (using sorter since a is not necessarily sorted).\n",
    "    # Then trace it back to original order with indexing into sidx\n",
    "    # Finally index into values for desired output.\n",
    "    return v[sidx[np.searchsorted(k,ar,sorter=sidx)]]\n",
    "\n",
    "\n",
    "unique_ids = np.sort(pd.unique(pd_content[\"paper_id\"]))\n",
    "nr_of_ids = len(unique_ids)\n",
    "\n",
    "# create dictionary for new indices\n",
    "dictionary = pd_content[\"paper_id\"].to_dict()\n",
    "inv_dict = {v: k for k, v in dictionary.items()}\n",
    "\n",
    "# replace indices\n",
    "edges = replace_with_dict(cora_cites,inv_dict)\n",
    "edges = np.array(edges)\n",
    "\n",
    "# create adjacency matrix\n",
    "adjacency = np.zeros((nr_of_papers, nr_of_papers), dtype=int)\n",
    "\n",
    "dataset = pd.DataFrame({'id1': edges[:, 0], 'id2': edges[:, 1]})\n",
    "for idx, row in dataset.iterrows():\n",
    "    i, j = int(row.id1), int(row.id2)\n",
    "    adjacency[i, j] = 1  # weight\n",
    "    adjacency[j, i] = 1  # weight to obtain an undirected network\n",
    "    \n",
    "#adjacency[:15, :15]\n",
    "\n",
    "A_citation = adjacency\n",
    "A_citation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_citation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(A_citation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the adjacency matrix of the citation graph for the field that you chose.\n",
    "You have to appropriately reduce the adjacency matrix of the citation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Warning Adjacenecy matrix is A_citation, NOT A_citation_feat\n",
    "for all the _features stuff we use A_feature\n",
    "'''\n",
    "my_field_columns = np.where(np.asarray([my_field_mask]))[1].tolist()\n",
    "\n",
    "A_citation = A_citation[:,my_field_columns]\n",
    "A_citation = A_citation[my_field_columns,:]\n",
    "A_citation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if your adjacency matrix is symmetric. Symmetrize your final adjacency matrix if it's not already symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(A_citation - A_citation.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of your adjacency matrix again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_citation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Degree Distribution and Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the total number of edges in each graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_edges_feature = np.count_nonzero(A_feature)/2 \n",
    "num_edges_citation = np.count_nonzero(A_citation)/2 \n",
    "print(f\"Number of edges in the feature graph: {num_edges_feature}\")\n",
    "print(f\"Number of edges in the citation graph: {num_edges_citation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the degree distribution histogram for each of the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_citation = np.sum(A_citation, axis=0)\n",
    "degrees_feature = np.sum(A_feature, axis=0)\n",
    "\n",
    "deg_hist_normalization = np.ones(degrees_citation.shape[0]) / degrees_citation.shape[0]\n",
    "deg_hist_normalization_feat = np.ones(degrees_feature.shape[0]) / degrees_feature.shape[0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4));\n",
    "_=axes[0].set_title('Citation graph degree distribution')\n",
    "_=axes[0].hist(degrees_citation, weights=deg_hist_normalization);\n",
    "_=axes[0].set_yscale('log')\n",
    "_=axes[1].set_title('Feature graph degree distribution')\n",
    "_=axes[1].hist(degrees_feature, weights=deg_hist_normalization_feat);\n",
    "_=axes[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the first and second moments of the degree distribution of each graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit_moment_1 = np.mean(degrees_citation)\n",
    "cit_moment_2 = np.mean(degrees_citation**2)\n",
    "\n",
    "feat_moment_1 = np.mean(degrees_feature)\n",
    "feat_moment_2 = np.mean(degrees_feature**2)\n",
    "\n",
    "cit_std = np.std(degrees_citation)\n",
    "feat_std = np.std(degrees_citation)\n",
    "\n",
    "print(f\"1st moment of citation graph: \\t{cit_moment_1:.2f}\")\n",
    "print(f\"2nd moment of citation graph: \\t{cit_moment_2:.2f}\")\n",
    "print(f\"std of citation graph: \\t\\t{cit_std:.2f}\\n\")\n",
    "\n",
    "print(f\"1st moment of feature graph: \\t{feat_moment_1:.2f}\")\n",
    "print(f\"2nd moment of feature graph: \\t{feat_moment_2:.2f}\")\n",
    "print(f\"std of citation graph: \\t\\t{feat_std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What information do the moments provide you about the graphs?\n",
    "Explain the differences in moments between graphs by comparing their degree distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**  \n",
    "Calculating the 1st and the 2nd moment from the respective degree distributions gives us the average degree and the standard deviation. \n",
    "For all citations we can see that there exists a very small probability for having a high degree node (hub). This increases the first and even more significantly the second moment leading to a standard deviation bigger than the mean degree and thus indicating behaviour of a scale free network.  \n",
    "For the selected feature graph the histogram shows that the degrees have a lower spread (lower first and second moment) which is anticipated since it is a subset of the citation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the 20 largest hubs for each of the graphs and remove them. Observe the sparsity pattern of the adjacency matrices of the citation and feature graphs before and after such a reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_node_ind = (degrees_citation.argsort()[:-20])\n",
    "reduced_A_citation = A_citation[:,small_node_ind]\n",
    "reduced_A_citation = reduced_A_citation[small_node_ind,:]\n",
    "\n",
    "small_node_ind = (degrees_feature.argsort()[:-20])\n",
    "reduced_A_feature = A_feature[:,small_node_ind]\n",
    "reduced_A_feature = reduced_A_feature[small_node_ind,:]\n",
    "\n",
    "small_node_ind = np.sort(degrees_citation.argsort()[-20:])\n",
    "largestHubs = A_citation[:,small_node_ind]\n",
    "largestHubs = largestHubs[small_node_ind,:]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "_=axes[0, 0].set_title('Feature graph: adjacency matrix sparsity pattern')\n",
    "_=axes[0, 0].spy(A_feature);\n",
    "_=axes[0, 0].set_xlim([0,len(A_feature)])\n",
    "_=axes[0, 1].set_title('Feature graph without top 20 hubs: adjacency matrix sparsity pattern')\n",
    "_=axes[0, 1].spy(reduced_A_feature);\n",
    "_=axes[1, 0].set_title('Citation graph: adjacency matrix sparsity pattern')\n",
    "_=axes[1, 0].spy(A_citation);\n",
    "_=axes[1, 1].set_title('Citation graph without top 20 hubs: adjacency matrix sparsity pattern')\n",
    "_=axes[1, 1].spy(reduced_A_citation);\n",
    "largestHubs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the new degree distribution histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_degrees_feat = np.sum(reduced_A_feature, axis=0)# Your code here.\n",
    "reduced_degrees_cit = np.sum(reduced_A_citation, axis=0)# Your code here.\n",
    "\n",
    "deg_hist_normalization = np.ones(reduced_degrees_cit.shape[0])/reduced_degrees_cit.shape[0]\n",
    "deg_hist_normalization_feat = np.ones(reduced_degrees_feat.shape[0]) / reduced_degrees_feat.shape[0]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "_=axes[0].set_title('Citation graph degree distribution')\n",
    "_=axes[0].hist(reduced_degrees_cit, weights=deg_hist_normalization);\n",
    "_=axes[0].set_yscale('log')\n",
    "_=axes[1].set_title('Feature graph degree distribution')\n",
    "_=axes[1].hist(reduced_degrees_feat, weights=deg_hist_normalization_feat);\n",
    "_=axes[1].set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the first and second moments for the new graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_cit_moment_1 = np.mean(reduced_degrees_cit)\n",
    "reduced_cit_moment_2 = np.mean(reduced_degrees_cit**2)\n",
    "\n",
    "reduced_feat_moment_1 = np.mean(reduced_degrees_feat)\n",
    "reduced_feat_moment_2 = np.mean(reduced_degrees_feat**2)\n",
    "\n",
    "reduced_cit_std = np.std(reduced_degrees_cit)\n",
    "reduced_feat_std = np.std(reduced_degrees_feat)\n",
    "\n",
    "print(f\"Citation graph first moment: \\t{reduced_cit_moment_1:.2f}\")\n",
    "print(f\"Citation graph second moment: \\t{reduced_cit_moment_2:.2f}\")\n",
    "print(f\"std of citation graph: \\t\\t{reduced_cit_std:.2f}\\n\")\n",
    "\n",
    "print(f\"Feature graph first moment: \\t{reduced_feat_moment_1:.2f}\")\n",
    "print(f\"Feature graph second moment: \\t{reduced_feat_moment_2:.2f}\")\n",
    "print(f\"std of feature graph: \\t\\t{reduced_feat_std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of edges in the reduced graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "num_edges_reduced_feature = reduced_degrees_feat.sum()/2\n",
    "num_edges_reduced_citation = reduced_degrees_cit.sum()/2\n",
    "print(f\"Number of edges in the feature graph: \\t{num_edges_reduced_feature}\")\n",
    "print(f\"Number of edges in the citation graph: \\t{num_edges_reduced_citation}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print relative change\n",
    "print(f\"Relative change: Citation graph first moment: \\t{(reduced_cit_moment_1/cit_moment_1-1)*100:.0f} %\")\n",
    "print(f\"Relative change: Citation graph second moment: \\t{(reduced_cit_moment_2/cit_moment_2-1)*100:.0f} %\")\n",
    "print(f\"Relative change: std of citation graph: \\t{(reduced_cit_std/cit_std-1)*100:.0f} %\\n\")\n",
    "\n",
    "print(f\"Relative change: Feature graph first moment: \\t{(reduced_feat_moment_1/feat_moment_1-1)*100:.0f} %\")\n",
    "print(f\"Relative change: Feature graph second moment: \\t{(reduced_feat_moment_2/feat_moment_2-1)*100:.0f} %\")\n",
    "print(f\"Relative change: std of feature graph: \\t\\t{(reduced_feat_std/feat_std-1)*100:.0f} %\\n\")\n",
    "\n",
    "print(f\"Relative change: Number of edges in the feature graph:  \\t{(num_edges_reduced_feature/num_edges_feature-1)*100:.0f} %\")\n",
    "print(f\"Relative change: Number of edges in the citation graph: \\t{(num_edges_reduced_citation/num_edges_citation-1)*100:.0f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the effect of removing the hubs the same for both networks? Look at the percentage changes for each moment. Which of the moments is affected the most and in which graph? Explain why.  \n",
    "\n",
    "**Hint:** Examine the degree distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees_citation_sorted = np.sort(degrees_citation)[::-1]\n",
    "degrees_feature_sorted = np.sort(degrees_feature)[::-1]\n",
    "n = 30\n",
    "degrees_citation_sorted[:n]\n",
    "degrees_feature_sorted[:n]\n",
    "\n",
    "n = 100\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "_=axes[0].set_title('Citation graph degree distribution')\n",
    "_=axes[0].plot(degrees_citation_sorted[:n]);\n",
    "_=axes[1].set_title('Feature graph degree distribution')\n",
    "_=axes[1].plot(degrees_feature_sorted[:n]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "### may need changes due to update A_feature\n",
    "Removing the 20 largest hubs significantly affects the second order. This behaviour is reasonable since, due to its definition, it depends on the square of the values and is thus strongly influenced by large values. The first order reduces too, however, considerably less. Furthermore the change is bigger for the feature graph which can be attributet to the fact that we removed the 20 biggest hubs in both cases, meaning that higher percentage of the big hubs in the feature graph has been removed compared to the citation graph due to the different total size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Pruning, sparsity, paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adjusting the threshold of the euclidean distance matrix, prune the feature graph so that its number of edges is roughly close (within a hundred edges) to the number of edges in the citation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_pruned = 3.59\n",
    "a = 0\n",
    "i = 0\n",
    "diff = 100;\n",
    "while abs(diff) > 10 and i < 1:\n",
    "    if diff > 0:\n",
    "        a += .01\n",
    "    else:\n",
    "        a -= .01\n",
    "    i += 1\n",
    "    \n",
    "    threshold_pruned = threshold_pruned - a\n",
    "\n",
    "    A_feature_pruned = (distance < threshold_pruned).astype(int)\n",
    "\n",
    "    # don't count \"self-edge\" diagonale\n",
    "    n = A_feature_pruned.shape[0]\n",
    "    A_feature_pruned[range(n),range(n)] = 0\n",
    "\n",
    "    num_edges_feature_pruned = np.count_nonzero(A_feature_pruned)/2\n",
    "    diff = num_edges_feature_pruned-num_edges_feature\n",
    "    #diff\n",
    "    #print(f\"{a:.4}\")\n",
    "    \n",
    "threshold_pruned\n",
    "\n",
    "print(f\"Number of edges in the feature graph: \\t\\t\\t{num_edges_feature}\")\n",
    "print(f\"Number of edges in the feature graph after pruning: \\t{num_edges_feature_pruned}\")\n",
    "print(f\"Number of edges in the citation graph: \\t\\t\\t{num_edges_citation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your results by comparing the sparsity patterns and total number of edges between the graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].set_title('Citation graph sparsity')\n",
    "axes[0].spy(A_citation);\n",
    "axes[1].set_title('Feature graph sparsity')\n",
    "axes[1].spy(A_feature_pruned);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $C_{k}(i,j)$ denote the number of paths of length $k$ from node $i$ to node $j$. \n",
    "\n",
    "We define the path matrix $P$, with entries\n",
    "$ P_{ij} = \\displaystyle\\sum_{k=0}^{N}C_{k}(i,j). $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the path matrices for both the citation and the unpruned feature graphs for $N =10$.  \n",
    "\n",
    "**Hint:** Use [powers of the adjacency matrix](https://en.wikipedia.org/wiki/Adjacency_matrix#Matrix_powers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_path_matrix(adjacency_matrix, N=10):\n",
    "    tmp = np.copy(adjacency_matrix)\n",
    "    paths_of_length_k = np.zeros(N)\n",
    "    paths_of_length_k[0] = np.count_nonzero(tmp)\n",
    "    path_matrix = np.eye(tmp.shape[0]) + tmp # we consider the 0-lenght path (adjecency_matrix ** 0 = identity matrix)\n",
    "    for n in range(1, N):\n",
    "        tmp = np.matmul(adjacency_matrix, tmp)\n",
    "        tmp[np.nonzero(tmp)] = 1 # remove multiple path count for counting higher deg. paths\n",
    "        #np.fill_diagonal(tmp, 0)\n",
    "        path_matrix += tmp\n",
    "        paths_of_length_k[n] = np.count_nonzero(tmp)\n",
    "    paths_of_length_k = paths_of_length_k / path_matrix.size\n",
    "    #np.fill_diagonal(path_matrix, 0)\n",
    "    return path_matrix, paths_of_length_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_matrix_citation, citation_paths_of_length_k = compute_path_matrix(A_citation)\n",
    "path_matrix_feature, feature_paths_of_length_k = compute_path_matrix(A_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the sparsity pattern for both of path matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 9))\n",
    "axes[0].set_title('Citation Path matrix sparsity')\n",
    "axes[0].spy(path_matrix_citation);\n",
    "axes[1].set_title('Feature Path matrix sparsity')\n",
    "axes[1].spy(path_matrix_feature);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calculate the path matrix of the pruned feature graph for $N=10$. Plot the corresponding sparsity pattern. Is there any difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_matrix_pruned, feature_pruned_paths_of_length_k = compute_path_matrix(A_feature_pruned)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title('Feature pruned Path matrix sparsity')\n",
    "plt.spy(path_matrix_pruned);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(path_matrix_citation)\n",
    "len(path_matrix_citation.flatten())\n",
    "\n",
    "np.count_nonzero(path_matrix_feature)\n",
    "len(path_matrix_feature.flatten())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "_=axes[0].set_title('Citation graph nr of paths (normalized) vs pathlength')\n",
    "_=axes[0].plot(citation_paths_of_length_k);\n",
    "_=axes[1].set_title('Feature graph nr of paths (normalized) vs pathlength')\n",
    "_=axes[1].plot(feature_paths_of_length_k);\n",
    "_=axes[2].set_title('Feature graph nr of paths (normalized) vs pathlength')\n",
    "_=axes[2].plot(feature_pruned_paths_of_length_k);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** The path matrix of the feature and the pruned feature graphs do show some discernible difference. In fact, the pruned feature graphs appears to have more connections between the nodes than the feature graph since the sparsity plot shows more entries. However, this result might be wrong since in the pruned feature graph the biggest hubs have been removed the contrary would be anticipated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe how you can use the above process of counting paths to determine whether a graph is connected or not. Is the original (unpruned) feature graph connected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** The path matrix shows how many paths of a length shorter or equal to a chosen length each node has. Therefore, if the number of entries in the path matrix converges to the number of nodes for path matrices with increased path length, this essentially means that at this path length all nodes are connected with at most this path length. As can be seen in the plot above the feature graph is connected with paths of maximum length of two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the graph is connected, how can you guess its diameter using the path matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** By iteratively increasing the exponent of the path matrix and checking if all entries are bigger than zero (connected with less than the path length given by the exponent) the diameter can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any of your graphs is connected, calculate the diameter using that process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = -1\n",
    "for n, elem in enumerate(feature_paths_of_length_k):\n",
    "    if elem == old:\n",
    "        diameter = n\n",
    "        break\n",
    "    else:\n",
    "        old = elem    \n",
    "    \n",
    "print(f\"The diameter is: {diameter}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if your guess was correct using [NetworkX](https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.distance_measures.diameter.html).\n",
    "Note: usage of NetworkX is only allowed in this part of Section 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "feature_graph = nx.from_numpy_matrix(A_feature)\n",
    "print(f\"Diameter according to networkx: {nx.diameter(feature_graph)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Network Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will analyze the feature and citation graphs you constructed in the previous section in terms of the network model types.\n",
    "For this purpose, you can use the NetworkX libary imported below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create NetworkX graph objects from the adjacency matrices computed in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_citation = nx.from_numpy_matrix(A_citation)\n",
    "print('Number of nodes: {}, Number of edges: {}'. format(G_citation.number_of_nodes(), G_citation.number_of_edges()))\n",
    "print('Number of self-loops: {}, Number of connected components: {}'. format(G_citation.number_of_selfloops(), nx.number_connected_components(G_citation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rest of this assignment, we will consider the pruned feature graph as the feature network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_feature = nx.from_numpy_matrix(A_feature_pruned)\n",
    "print('Number of nodes: {}, Number of edges: {}'. format(G_feature.number_of_nodes(), G_feature.number_of_edges()))\n",
    "print('Number of self-loops: {}, Number of connected components: {}'. format(G_feature.number_of_selfloops(), nx.number_connected_components(G_feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Simulation with Erdős–Rényi and Barabási–Albert models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Erdős–Rényi and a Barabási–Albert graph using NetworkX to simulate the citation graph and the feature graph you have. When choosing parameters for the networks, take into account the number of vertices and edges of the original networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of nodes should exactly match the number of nodes in the original citation and feature graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(G_citation.nodes()) == len(G_feature.nodes())\n",
    "n = len(G_citation.nodes())\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of match shall fit the average of the number of edges in the citation and the feature graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.round((G_citation.size() + G_feature.size()) / 2)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you determine the probability parameter for the Erdős–Rényi graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** The probability p, for the Erdős–Rényi model of any graph, is given by the number of links $m$ of this graph divided by the maximal number of links (unidirectional) possible for the available nodes $n*(n-1)/2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (2*m)/(n*(n-1))\n",
    "G_er = nx.erdos_renyi_graph(n, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of edges in the Erdős–Rényi graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('My Erdos-Rényi network that simulates the citation graph has {} edges.'.format(G_er.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you determine the preferential attachment parameter for Barabási–Albert graphs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** Preferential attachemnt of a given graph is the tendency (probability) that newly added nodes link to already highly linked nodes (high degree). This probability $\\Pi\\left(k_{i}\\right)$ that a link of the new node connects to node i can thus be given by $\\Pi\\left(k_{i}\\right)=\\frac{k_{i}}{\\sum_{j} k_{j}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = int(m/n)\n",
    "G_ba = nx.barabasi_albert_graph(n, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of edges in the Barabási–Albert graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('My Barabási-Albert network that simulates the citation graph has {} edges.'.format(G_ba.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Giant Component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the largest connected component in the citation and feature graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_citation = giant_citation = max(list(nx.connected_component_subgraphs(G_citation)), key = len)\n",
    "print('The giant component of the citation graph has {} nodes and {} edges.'.format(giant_citation.number_of_nodes(), giant_citation.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_feature =  max(list(nx.connected_component_subgraphs(G_feature)), key = len)\n",
    "print('The giant component of the feature graph has {} nodes and {} edges.'.format(giant_feature.number_of_nodes(), giant_feature.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the giant components in the generated Erdős–Rényi graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_er = max(list(nx.connected_component_subgraphs(G_er)), key = len)\n",
    "print('The giant component of the Erdos-Rényi network has {} nodes and {} edges.'.format(giant_er.number_of_nodes(), giant_er.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us match the number of nodes in the giant component of the feature graph by simulating a new Erdős–Rényi network.\n",
    "How do you choose the probability parameter this time? \n",
    "\n",
    "**Hint:** Recall the expected giant component size from the lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = giant_feature.number_of_nodes()\n",
    "p_new = (-np.log(1-(ng/n)))/((ng/n)*(n))\n",
    "G_er_new = nx.erdos_renyi_graph(n, p_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the size of the new Erdős–Rényi network and its giant component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('My new Erdos Renyi network that simulates the citation graph has {} edges.'.format(G_er_new.size()))\n",
    "giant_er_new = max(list(nx.connected_component_subgraphs(G_er_new)), key = len)\n",
    "print('The giant component of the new Erdos-Rényi network has {} nodes and {} edges.'.format(giant_er_new.number_of_nodes(), giant_er_new.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Degree Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the degree distribution of the citation and the feature graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "axes[0].set_title('Citation graph')\n",
    "citation_degrees = [G_citation.degree(n) for n in G_citation.nodes()]\n",
    "axes[0].hist(citation_degrees, bins = range(min(citation_degrees), max(citation_degrees)));\n",
    "axes[1].set_title('Feature graph')\n",
    "feature_degrees = [G_feature.degree(n) for n in G_feature.nodes()]\n",
    "axes[1].hist(feature_degrees, bins = range(min(citation_degrees), max(citation_degrees)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the degree distribution tell us about a network? Can you make a prediction on the network model type of the citation and the feature graph by looking at their degree distributions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** By observing both histograms we can see that the number of nodes decreases sharply as the degree increases. It doesn't seem to fit the bell curve that can form a binomial or poisson distribution. Furthermore, by plotting the logarithmic graphs, we can have a better observation of the degree distribution. Let $p_{k}$ be the frequency of the $k$ degree, we can actually see for the citation graph that $log(p_k) \\sim - \\alpha k $. According to the course, we shall consider that the model that best fit this graph is the scale-free model despite the fact that the distribution doesn't match : it should be $log(p_k) \\sim -\\gamma log(k)$\n",
    "Also we cannot make any conclusion about the degree distribution for the feature graph. However \n",
    "definit la power law\n",
    "//We observe that the degree distribution is mostly zero for both graphs. \n",
    "(idée : citation graph, nouveau bouquin cite ancien + hubs = crédibilité)\n",
    "In the citation graph we mostly observe that nodes have zero degree distribution and \n",
    "The scale-free behavior of the citation graph could come from the fact that the books are publihed one at a time and considering that here every book are in the same category, the new ones would cite the older ones (growth property) and the more cited books get a scientific credibility that forces the new publication to refer to them intead of the others (preferential attachment propertiy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot the degree distribution historgrams for the simulated networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "axes[0].set_title('Citation graph')\n",
    "citation_degrees = [G_citation.degree(n) for n in G_citation.nodes()]\n",
    "values, counts = np.unique(citation_degrees,return_counts=True)\n",
    "counts = counts / len(feature_degrees)\n",
    "axes[0].plot(values,counts,'o');\n",
    "axes[1].set_title('Feature graph')\n",
    "feature_degrees = [G_feature.degree(n) for n in G_feature.nodes()]\n",
    "values, counts = np.unique(feature_degrees,return_counts=True)\n",
    "counts = counts / len(feature_degrees)\n",
    "axes[1].plot(values,counts,'o');\n",
    "\n",
    "#axes[0].set_xscale('log')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlabel(\"k\")\n",
    "axes[0].set_ylabel(\"$p_k$\")\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlabel(\"k\")\n",
    "axes[1].set_ylabel(\"$p_k$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "axes[0].set_title('Erdos-Rényi network')\n",
    "er_degrees = [G_er.degree(n) for n in G_er.nodes()]\n",
    "axes[0].hist(er_degrees);\n",
    "axes[1].set_title('Barabási-Albert network')\n",
    "ba_degrees = [G_ba.degree(n) for n in G_ba.nodes()]\n",
    "axes[1].hist(ba_degrees);\n",
    "axes[2].set_title('new Erdos-Rényi network')\n",
    "er_new_degrees = [G_er_new.degree(n) for n in G_er_new.nodes()]\n",
    "axes[2].hist(er_new_degrees);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of the degree distribution, is there a good match between the citation and feature graphs and the simulated networks?\n",
    "For the citation graph, choose one of the simulated networks above that match its degree distribution best. Indicate your preference below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also simulate a network using the configuration model to match its degree disctribution exactly. Refer to [Configuration model](https://networkx.github.io/documentation/stable/reference/generated/networkx.generators.degree_seq.configuration_model.html#networkx.generators.degree_seq.configuration_model).\n",
    "\n",
    "Let us create another network to match the degree distribution of the feature graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_config = nx.configuration_model(feature_degrees, create_using = nx.Graph) \n",
    "print('Configuration model has {} nodes and {} edges.'.format(G_config.number_of_nodes(), G_config.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it mean that we create the same graph with the feature graph by the configuration model? If not, how do you understand that they are not the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:** (TO DOUBLE CHECK) Even though the new graph with configuration_mode that follow the same degree distribution of the feature graph, it does not mean that they may represent the same structure of the graph as the clustering structure may change or the number of connected components even though they have the same degree distribution. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: Clustering Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the average clustering coefficient of the original citation and feature graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(G_citation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(G_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the clustering coefficient tell us about a network? Comment on the values you obtain for the citation and feature graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us check the average clustering coefficient for the simulated networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(G_er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(G_ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(nx.Graph(G_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the values you obtain for the simulated networks. Is there any good match to the citation or feature graph in terms of clustering coefficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the other [network model generators](https://networkx.github.io/documentation/networkx-1.10/reference/generators.html) provided by NetworkX. Which one do you predict to have a better match to the citation graph or the feature graph in terms of degree distribution and clustering coefficient at the same time? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find a better fit, create a graph object below for that network model. Print the number of edges and the average clustering coefficient. Plot the histogram of the degree distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ci_clust = nx.powerlaw_cluster_graph(int(n/2), 2, (np.log(int(n/2)) ** 2)/ (int(n/2) ** 2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ci_clust.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on the similarities of your match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.average_clustering(g_ci_clust)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
