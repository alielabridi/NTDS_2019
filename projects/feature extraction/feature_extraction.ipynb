{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction from preprocessed data\n",
    "Relevant features are extracted directly from the relations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "def restart_line():\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "filenames =['relations_extended.csv']\n",
    "\n",
    "path = \"/Users/jonasmuller/Local_Folder/Project NTDS/\"\n",
    "file = path + filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Nr: 1717; feature shhape: (5399965, 4)\n",
      "Execution time 23 min 16.31 sec\n",
      "number of cycles 1717\n"
     ]
    }
   ],
   "source": [
    "chunksize = 1000000\n",
    "i = 0\n",
    "carry = pd.DataFrame()\n",
    "df_buffer = pd.DataFrame()\n",
    "features = pd.DataFrame()\n",
    "rel_dist = pd.DataFrame(np.zeros(7),list(range(1,8)),columns=[\"count\"])\n",
    "t1 = time.time()\n",
    "for chunk in pd.read_csv(file, chunksize=chunksize, sep = \"\\t\", names=[\"day\", \"time_ms\", \"src\", \"dst\",\"relation\"]):\n",
    "    \n",
    "    # slice chunk at specific src\n",
    "    chunk = chunk.append(carry)\n",
    "    \n",
    "    # remove last source in chunk\n",
    "    last_src = np.unique(chunk[\"src\"].values)[-1]\n",
    "    carry = chunk.loc[chunk[\"src\"] == last_src]\n",
    "    \n",
    "    chunk = chunk.loc[chunk[\"src\"] != last_src]\n",
    "    sources_in_chunk = np.unique(chunk[\"src\"].values)\n",
    "    \n",
    "    # count number of out degrees\n",
    "    degree_tot = chunk.groupby('src').dst.count()\n",
    "    degree_out = chunk.loc[chunk[\"relation\"] < 10].groupby('src').dst.count()\n",
    "    degree_in = chunk.loc[chunk[\"relation\"] > 10].groupby('src').dst.count()\n",
    "    \n",
    "    # count number of unique neighbors\n",
    "    unique_neighbors = chunk.groupby('src').dst.nunique()\n",
    "    \n",
    "    # bidirectional relations\n",
    "    # intersection between in and out relation nodes\n",
    "    \n",
    "    # weights acording to relation scarcity (then deg in deg out) / number of strong connections per node\n",
    "    \n",
    "    # relation distribution count\n",
    "    values, counts = np.unique(chunk.loc[chunk[\"relation\"] < 10].relation.values, return_counts=True)\n",
    "    rel_dist = rel_dist.add(pd.Series(counts, index=values),axis='index')\n",
    "    \n",
    "    # append degrees\n",
    "    df_buffer['deg_tot'] = pd.Series(degree_tot)\n",
    "    df_buffer['deg_out'] = pd.Series(degree_out)\n",
    "    df_buffer['deg_in'] = pd.Series(degree_in)\n",
    "    df_buffer['uni_neigh'] = pd.Series(unique_neighbors)\n",
    "    \n",
    "    features = features.append(df_buffer)\n",
    "    \n",
    "    # break for debugging\n",
    "    i = i+1\n",
    "    if i < 1:\n",
    "        break\n",
    "        \n",
    "    restart_line()\n",
    "    sys.stdout.write(f'Chunk Nr: {i}; feature shhape: {features.shape}')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# print relevant key data\n",
    "m = math.floor((time.time()-t1)/60)\n",
    "s = (time.time()-t1)-m*60\n",
    "print(f'\\nExecution time {m} min {s:.2f} sec')\n",
    "print(f'number of cycles {i}')\n",
    "\n",
    "# statistics\n",
    "total_relations = np.sum(rel_dist.values)\n",
    "rel_dist = rel_dist.div(total_relations)\n",
    "with open(\"Output.txt\", \"w\") as text_file:\n",
    "    print(f\"Nr of total relations: {total_relations}\\n\", file=text_file)\n",
    "    print(rel_dist, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "ax = plt.figure(1, figsize=(15, 3))\n",
    "plt.title(\"DegreeOut histogram\")\n",
    "plt.hist(dout.values, bins=200);\n",
    "plt.ylabel('Number of Nodes')\n",
    "plt.xlabel('Degree Out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relations_extended_features.csv\n"
     ]
    }
   ],
   "source": [
    "# save features\n",
    "exportName = filenames[0][:-4] + \"_features.csv\"\n",
    "print(exportName)\n",
    "features.to_csv(exportName, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
