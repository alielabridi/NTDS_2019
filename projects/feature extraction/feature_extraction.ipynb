{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction from preprocessed data\n",
    "Relevant features are extracted directly from the relations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "def restart_line():\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "filenames =['relations_extended.csv']\n",
    "\n",
    "path = \"/Users/jonasmuller/Local_Folder/Project NTDS/\"\n",
    "file = path + filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Nr: 1717; feature shhape: (5321960, 3)\n",
      "Execution time 23 min 2.21 sec\n",
      "number of cycles 1717\n",
      "relations_extended_features.csv\n"
     ]
    }
   ],
   "source": [
    "chunksize = 1000000\n",
    "i = 0\n",
    "carry = pd.DataFrame()\n",
    "df_buffer = pd.DataFrame()\n",
    "features = pd.DataFrame()\n",
    "rel_dist = pd.DataFrame(np.zeros(7),list(range(1,8)),columns=[\"count\"])\n",
    "t1 = time.time()\n",
    "print(f\"Number of Chunks: {np.ceil(1716494198/chunksize)}\")\n",
    "for chunk in pd.read_csv(file, chunksize=chunksize, sep = \"\\t\", names=[\"day\", \"time_ms\", \"src\", \"dst\",\"relation\"]):\n",
    "    \n",
    "    # slice chunk at specific src\n",
    "    chunk = carry.append(chunk)\n",
    "    \n",
    "    # remove last source in chunk\n",
    "    last_src = np.unique(chunk[\"src\"].values)[-1]\n",
    "    carry = chunk.loc[chunk[\"src\"] == last_src]\n",
    "    \n",
    "    chunk = chunk.loc[chunk[\"src\"] != last_src]\n",
    "    sources_in_chunk = np.unique(chunk[\"src\"].values)\n",
    "    \n",
    "    # count number of out degrees\n",
    "    degree_tot = chunk.groupby('src').dst.count()\n",
    "    degree_out = chunk.loc[chunk[\"relation\"] < 10].groupby('src').dst.count()\n",
    "    \n",
    "    \n",
    "    # count number of unique neighbors\n",
    "    unique_neighbors = chunk.groupby('src').dst.nunique()\n",
    "    \n",
    "    # bidirectional relations\n",
    "    # intersection between in and out relation nodes\n",
    "    \n",
    "    # weights acording to relation scarcity (then deg in deg out) / number of strong connections per node\n",
    "    \n",
    "    # relation distribution count\n",
    "    values, counts = np.unique(chunk.loc[chunk[\"relation\"] < 10].relation.values, return_counts=True)\n",
    "    rel_dist = rel_dist.add(pd.Series(counts, index=values),axis='index')\n",
    "    \n",
    "    # append degrees\n",
    "    df_buffer = df_buffer[0:0]\n",
    "    df_buffer['deg_tot'] = pd.Series(degree_tot)\n",
    "    df_buffer['deg_out'] = pd.Series(degree_out)\n",
    "    df_buffer['uni_neigh'] = pd.Series(unique_neighbors)\n",
    "    \n",
    "    df_buffer = df_buffer.fillna(0)\n",
    "    \n",
    "    features = features.append(df_buffer)\n",
    "    \n",
    "    # break for debugging\n",
    "    i = i+1\n",
    "    if i < 1:\n",
    "        break\n",
    "        \n",
    "    restart_line()\n",
    "    sys.stdout.write(f'Chunk Nr: {i}; feature shhape: {features.shape}')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# print relevant key data\n",
    "m = math.floor((time.time()-t1)/60)\n",
    "s = (time.time()-t1)-m*60\n",
    "print(f'\\nExecution time {m} min {s:.2f} sec')\n",
    "print(f'number of cycles {i}')\n",
    "\n",
    "# statistics\n",
    "total_relations = np.sum(rel_dist.values)\n",
    "rel_dist = rel_dist.div(total_relations)\n",
    "with open(\"Output.txt\", \"w\") as text_file:\n",
    "    print(f\"Nr of total relations: {total_relations}\\n\", file=text_file)\n",
    "    print(rel_dist, file=text_file)\n",
    "\n",
    "# save features\n",
    "if True:\n",
    "    exportName = filenames[0][:-4] + \"_features.csv\"\n",
    "    print(exportName)\n",
    "    features.to_csv(exportName, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relations_extended_features.csv\n"
     ]
    }
   ],
   "source": [
    "# save features\n",
    "exportName = filenames[0][:-4] + \"_features.csv\"\n",
    "print(exportName)\n",
    "features.to_csv(exportName, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "ax = plt.figure(1, figsize=(15, 3))\n",
    "plt.title(\"DegreeOut histogram\")\n",
    "plt.hist(dout.values, bins=200);\n",
    "plt.ylabel('Number of Nodes')\n",
    "plt.xlabel('Degree Out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.memory_usage of       deg_tot  deg_out  uni_neigh\n",
      "src                              \n",
      "1       275.0     90.0      166.0\n",
      "2       294.0     59.0      189.0\n",
      "3        57.0     34.0       34.0\n",
      "4        36.0     13.0       21.0\n",
      "5        38.0     16.0       23.0\n",
      "...       ...      ...        ...\n",
      "3322      NaN      NaN        NaN\n",
      "3323      NaN      NaN        NaN\n",
      "3324      NaN      NaN        NaN\n",
      "3325      NaN      NaN        NaN\n",
      "3326      NaN      NaN        NaN\n",
      "\n",
      "[632145 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(features.memory_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
